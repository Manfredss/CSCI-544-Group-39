% !TEX root = ../main.tex

\section{Broader Impact}
This paper motivates and introduces a framework for investigating the problem of shortcut learning for contrastive \ac{VL} representation learning with multiple captions per image in a controlled way.
It also examines how two shortcut learning reduction methods perform on the proposed framework.
Overall, the framework provides a tool for analyzing and understanding the problem of shortcut learning in the context of contrastive \ac{VL} representation learning; it can be used in various settings that require deeper insight into the quality of learned \ac{VL} representations.


We should be aware that the reliance on shortcuts in \acp{VLM} poses ethical concerns with potential real-world implications. 
Models that learn shortcuts may overlook nuanced details in images and text, leading to biased or inaccurate outcomes. 
Furthermore, the transparency and explainability of \acp{VLM} are crucial considerations. 
Models that rely on shortcuts may make decisions based on features that are not easily interpretable or explainable to users. 
This lack of transparency can diminish trust in AI systems.

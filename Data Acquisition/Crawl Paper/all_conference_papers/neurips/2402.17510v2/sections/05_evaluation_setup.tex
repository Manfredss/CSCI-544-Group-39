% !TEX root = ../main.tex

\section{Reducing Shortcut Learning}
\label{sec:reducing_shortcut_solution}

In the earlier section, we have demonstrated that contrastive loss mainly relies on the minimal, easy-to-detect features shared among image-caption pairs while suppressing remaining task-relevant information.
In this section, we describe two methods that help to reduce shortcut learning for contrastive learning on our \ac{SVL} framework: \Acl{LTD}~\citep{bleeker2023reducing} and  \acl{IFM}~\citep{robinson2021can}. 

\subsection{Latent Target Decoding}  

\Acf{LTD}~\citep{bleeker2023reducing} is a method to reduce predictive feature suppression (i.e., shortcut learning) for resource-constrained contrastive image-caption matching. 
The contrastive objective (i.e., InfoNCE)  is combined with an additional reconstruction loss, which reconstructs the input caption from the latent representation of the caption $\zcapt{i}{j}$. 
We refer to Appendix~\ref{app:ltd} for the mathematical definition of \ac{LTD}.
Instead of reconstructing the tokens of the input caption in an auto-regressive manner (i.e., auto-encoding), the caption is reconstructed non-auto-regressively, by mapping the caption representation into the latent space of a \acl{SBERT}~\citep{reimersers2019sentence, song2020mpnet} and minimizing the distance (i.e., reconstructing) between the reconstruction and the \acl{SBERT} representation of the caption $\capt{i}{j}$. 
The assumption is that the \emph{target} generated by the \acl{SBERT} model contains all task-relevant information in the caption. 
Hence, by correctly mapping the latent caption representation $\zcapt{i}{j}$ into the latent space of \acl{SBERT}, the caption encoder cannot suppress any task-relevant information or rely on shortcut solutions. 
\ac{LTD} is implemented both as a dual-loss objective (i.e., the contrastive loss and \ac{LTD} are added up) and as an optimization constraint while minimizing the InfoNCE loss, by implementing the loss as a Lagrange multiplier. For the mathematical definition of \ac{LTD}, we refer to Appendix~\ref{app:ltd}.

\header{Experimental Setup} We use the \ac{LTD} implementation and set-up similar to \citet{bleeker2023reducing}. 
We train both CLIP and VSE++ with \ac{LTD}, implemented as either dual loss or an optimization constraint.
When implementing \ac{LTD} as a constraint, we try $\eta \in \{0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3\}$ as bound values.
Similar to \cite{bleeker2023reducing}, when implementing \ac{LTD} as a dual loss, we use $\beta=1$ as balancing parameters.   
We train both with and without unique shortcuts.  
We do this to show 
\begin{enumerate*}[label=(\roman*)]
	\item what the performance improvement is compared to using only InfoNCE, and 
	\item to what degree \ac{LTD} prevents full collapse to shortcut features.
\end{enumerate*}
For each model and dataset, we take the training setup that results in the highest performance on the validation set.

\subsection{Implicit Feature Modification} 
\Acf{IFM}~\citep{robinson2021can} is a method, originally introduced in the context of representation learning for images,
that applies perturbations to logits used for guiding contrastive models. 
\ac{IFM} perpetuates features that the encoders use during a training step to discriminate between positive and negative samples. 
By doing so, \ac{IFM} alters the features that are currently used to solve the discrimination task, to avoid the InfoNCE loss to learn shortcut solutions.  
How much of the features are removed, is defined by a perturbation budget $\epsilon$.
\ac{IFM} is implemented as a dual loss in combination with the InfoNCE loss. 
For the mathematical definition of \ac{IFM}, we refer to Appendix~\ref{app:ifm}.

\header{Experimental Setup}
We apply a similar experimental set-up for \ac{IFM} as for \ac{LTD}.
We apply \ac{IFM} both to CLIP and to VSE++, both with and without unique shortcuts.
Similar to \citep{robinson2021can}, we try different perturbation budgets $\epsilon$, we try $\epsilon \in \{0.05, 0.1, 0.2, 0.5, 1\}$.
In line with the \ac{LTD} setup, we take the training setup that results in the highest performance on the validation set.

\subsection{Method Comparison}
Both \ac{LTD} and \ac{IFM} aim to mitigate shortcut learning through different approaches.
\ac{LTD} aims to learn all task-relevant information by reconstructing the input captions.
In contrast, \ac{IFM} perturbs the discriminative features in the latent space of the encoder and does not rely on a reconstruction objective.
Overall, both methods represent distinct strategies for improving the robustness and generalization capabilities of \ac{VL} representation learning.

In the following section, we present experimental results with \ac{LTD} and \ac{IFM}, providing insight into their effectiveness in mitigating shortcut learning.

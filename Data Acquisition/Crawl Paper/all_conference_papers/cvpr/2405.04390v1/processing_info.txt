标题: DriveWorld: 4D Pre-trained Scene Understanding via World Models for Autonomous Driving
arXiv ID: 2405.04390v1
发布时间: 2024-05-07 15:14:20+00:00
作者: Chen Min, Dawei Zhao, Liang Xiao, Jian Zhao, Xinli Xu, Zheng Zhu, Lei Jin, Jianshu Li, Yulan Guo, Junliang Xing, Liping Jing, Yiming Nie, Bin Dai
摘要: Vision-centric autonomous driving has recently raised wide attention due to
its lower cost. Pre-training is essential for extracting a universal
representation. However, current vision-centric pre-training typically relies
on either 2D or 3D pre-text tasks, overlooking the temporal characteristics of
autonomous driving as a 4D scene understanding task. In this paper, we address
this challenge by introducing a world model-based autonomous driving 4D
representation learning framework, dubbed \emph{DriveWorld}, which is capable
of pre-training from multi-camera driving videos in a spatio-temporal fashion.
Specifically, we propose a Memory State-Space Model for spatio-temporal
modelling, which consists of a Dynamic Memory Bank module for learning
temporal-aware latent dynamics to predict future changes and a Static Scene
Propagation module for learning spatial-aware latent statics to offer
comprehensive scene contexts. We additionally introduce a Task Prompt to
decouple task-aware features for various downstream tasks. The experiments
demonstrate that DriveWorld delivers promising results on various autonomous
driving tasks. When pre-trained with the OpenScene dataset, DriveWorld achieves
a 7.5% increase in mAP for 3D object detection, a 3.0% increase in IoU for
online mapping, a 5.0% increase in AMOTA for multi-object tracking, a 0.1m
decrease in minADE for motion forecasting, a 3.0% increase in IoU for occupancy
prediction, and a 0.34m reduction in average L2 error for planning.
URL: http://arxiv.org/abs/2405.04390v1
图片输出目录: all_conference_papers/cvpr/2405.04390v1/extracted_images
LaTeX文件数量: 9
图片文件总数: 7
匹配图片数量: 7

==================================================
LaTeX文件列表:
  - all_conference_papers/cvpr/2405.04390v1/preamble.tex
  - all_conference_papers/cvpr/2405.04390v1/main.tex
  - all_conference_papers/cvpr/2405.04390v1/sec/4_experiments.tex
  - all_conference_papers/cvpr/2405.04390v1/sec/1_intro.tex
  - all_conference_papers/cvpr/2405.04390v1/sec/2_related_work.tex
  - all_conference_papers/cvpr/2405.04390v1/sec/X_suppl.tex
  - all_conference_papers/cvpr/2405.04390v1/sec/0_abstract.tex
  - all_conference_papers/cvpr/2405.04390v1/sec/3_method.tex
  - all_conference_papers/cvpr/2405.04390v1/sec/5_conclusion.tex

==================================================
图片引用列表:
  - results
  - compare
  - flowchart
  - occ
  - graph
  - task
  - mssm

==================================================
匹配的图片文件:
  - all_conference_papers/cvpr/2405.04390v1/figures/results.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/mssm.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/task.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/flowchart.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/graph.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/occ.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/compare.pdf

==================================================
所有图片文件:
  - all_conference_papers/cvpr/2405.04390v1/figures/results.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/mssm.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/task.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/flowchart.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/graph.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/occ.pdf
  - all_conference_papers/cvpr/2405.04390v1/figures/compare.pdf

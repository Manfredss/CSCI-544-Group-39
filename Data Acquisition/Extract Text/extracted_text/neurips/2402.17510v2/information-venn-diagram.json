{
  "summary": "Contrastive learning suppresses task-relevant information by prioritizing synthetic shortcuts.",
  "caption": "We define $H({})$ as image information, $H({A})$ and $H({B})$ as caption information; both captions only describe the information depicted in the image and contain shared and caption-specific information. We further define $C_A = I( {} ; {A} {B})$ and $C_B = I( {} ; {B} {A})$ as caption-specific information; $S = I({} ; {A} ; {B})$ as shared information; $ R = H( {} {A} , {B} ) $ as task-irrelevant information; $R = C_A + C_B + S$ as task-relevant information.",
  "label": "fig:venn",
  "extracted_context": "### Relevant Context Paragraphs\n\n#### 1. **Information Entropy and Task-Relevant Data (Figure Context)**  \n> \"We define $H({})$ as image information, $H({A})$ and $H({B})$ as caption information; both captions only describe the information depicted in the image and contain shared and caption-specific information. We further define $C_A = I( {} ; {A} {B})$ and $C_B = I( {} ; {B} {A})$ as caption-specific information; $S = I({} ; {A} ; {B})$ as shared information; $R = H( {} {A} , {B} )$ as task-relevant information; $R = C_A + C. $ as task-relevant information.\"\n\nThis paragraph defines the key information components (shared $S$, caption-specific $C_A, C_B$, and task-relevant $R$) discussed in the figure, establishing the theoretical framework for analyzing contrastive learning's suboptimality.\n\n---\n\n#### 2. **Suboptimality of Contrastive Losses (Theorem and Implications)**  \n> \"Theorem~\\ref{thm:suboptimality-main} indicates a discrepancy between minimally sufficient representations learned during contrastive training with the InfoNCE loss and the task-optimal image representations in the context of learning \\ac{VL} representations with multiple captions per image. Although the InfoMax loss does not have an explicit constraint to compress information, prior work indicates that feature suppression is happening \\citep{shwartz2023compress, robinson2021can}. Hence, we question if contrastive loss can be used to learn task-optimal image representations in the context of multiple captions per image.\"\n\nThis section explicitly connects the theoretical framework (shared/task-relevant information) to the suboptimality of contrastive losses, emphasizing how feature suppression during training leads to non-optimal representations.\n\n---\n\n#### 3. **Synthetic Shortcuts Framework (Experimental Setup)**  \n> \"In this section, we introduce the \\textit{\\acf{SVL}} training and evaluation framework. We denote the \\textit{synthetic shortcuts for image-caption data} as $\\sct{}$. The purpose of the framework is to introduce additional and easily identifiable information shared between an image and the matching captions that lacks any semantic meaning. The shortcuts we use in this work are represented as numbers that we add to images and captions.\"\n\nThis paragraph introduces the synthetic shortcut method as a controlled experimental tool to test the hypothesis that contrastive learning suppresses task-relevant information. It directly ties to the figure's information components by creating synthetic shared information ($S^+$) and task-relevant information ($R^+$).\n\n---\n\n#### 4. **Impact of Synthetic Shortcuts on Task-Relevance**  \n> \"If contrastive losses learn task-optimal representations, then the presence of synthetic shortcuts should not negatively impact the evaluation performance, since synthetic shortcuts represent additional information and the remaining task-relevant information is intact. By incorporating synthetic shortcuts into the image-caption dataset, the shared information would include the information that was originally shared and the synthetic shortcut: $S^{+} = S + \\sct{}$. Hence, the task-relevant information would comprise caption-specific information that was originally shared and a synthetic shortcut: $R^{+} = C_A + C_B + S + \\sct{}$. If injecting a synthetic shortcut influences the performance negatively, we can conclude that by learning to represent a synthetic shortcut the model suppresses other task-relevant information in favor of the shortcut, hence the representation is not task-optimal.\"\n\nThis section directly applies the information components from the figure to analyze the synthetic shortcut experiment, linking the theoretical framework to empirical testing of suboptimality.\n\n---\n\n#### 5. **Experimental Setups (Baseline and Variants)**  \n> \"We define the following experimental setups:  \n1. \\emph{No shortcuts}: As a baseline, we fine-tune a pre-trained CLIP~\\citep{radford2021learning} and train VSE++~\\citep{faghri2018improving} from scratch on \\ac{Flickr30k} and \\ac{MS-COCO}, without using any shortcuts.  \n2. \\emph{Unique shortcuts}: We add a unique shortcut to each image-caption tuple $i \\in\\mathcal{D}$ in the dataset.  \n3. \\emph{Unique shortcuts on only one modality}: To show that the shortcuts do not interfere with the original task-relevant information ($S, C_A$, and $C_B$) of the images and captions, we create a dataset with only shortcuts on either the image or caption modality.  \n4. \\emph{N bits of shortcuts}: In this setup, for each image-caption pair in the training batch $\\mathcal{B}$, we randomly sample a shortcut number from the range $[0, 2^{n}]$, where $n$ is the number of bits. The higher the value of $n$, the more image-caption pairs in the training batch will have by expectation a unique shortcut, and, the less the model has to rely on $S$ and the remaining task-relevant information to solve the contrastive objective.\"\n\nThese setups directly tie the figure's information components to the experimental design, testing how synthetic shortcuts (as additional shared information) affect model performance and task-relevance.",
  "extraction_method": "LLM-based"
}
{
  "summary": "The figure illustrates a memory-based adapter that caches and fuses 3D voxel features using a queue and attention mec...",
  "caption": "The architecture of the memory-based adapter for point cloud features. We cache and aggregate the features in a queue of 3D voxel grids. Gray, green, yellow and red block refer to previous, current, updated and aggregated voxel features.",
  "label": "point-module",
  "extracted_context": "### 相关上下文段落提取\n\n1. **内存基适配器的架构描述**  \n   - **图标注：point-module**  \n     *图示：内存基适配器的点云特征架构。我们通过一个3D体素网格队列缓存并聚合特征。灰色、绿色、黄色和红色块分别代表先前、当前、更新和聚合的体素特征。*  \n     （见原文中 **Figure Label (if any): point-module** 的图注）\n\n2. **详细架构部分**  \n   - 在 **Section \\ref{architecture}** 中，作者详细描述了如何将内存基适配器插入到图像和点云主干网络中。  \n     - **点云主干网络**：使用 **Minkowski-UNet** 或 **TD3D**，并引入内存基适配器以增强特征。  \n     - **关键设计**：通过队列缓存高分辨率场景表示（如TD3D的ROI级实例预测），确保每个ROI内的点云最完整。  \n     - **3D NMS策略**：通过简单聚合实现完整的实例掩码，避免复杂掩码融合策略（如 \\cite{liu2022ins}）。\n\n3. **适配器的数学定义与流程**  \n   - **队列机制**：  \n     $$\n     \\text{Queue}_{t} = \\text{Queue}_{t-1} \\cup \\text{Current Features}_{t}\n     $$  \n     （队列在每帧更新时合并当前特征）  \n   - **特征聚合**：  \n     $$\n     \\text{Aggregated Features} = \\text{Attention}(\\text{Queue}_{t}, \\text{Current Features}_{t})\n     $$  \n     （通过注意力机制融合历史与当前特征）  \n   - **3D NMS掩码生成**：  \n     $$\n     \\text{Instance Mask}_{t} = \\text{3D NMS}(\\text{Aggregated Features}_{t})\n     $$  \n     （直接利用聚合特征生成实例掩码）\n\n4. **实验与结果**  \n   - **ScanNet数据集**：  \n     - 3D语义分割：平均IoU为 **72.7%**（见 **Table \\ref{supp:tab1}**）。  \n     - 3D目标检测：平均AP$_{50}$为 **56.7%**（见 **Table \\ref{supp:tab3}**）。  \n   - **SceneNN数据集**：  \n     - 3D语义分割：平均IoU为 **56.7%**（见 **Table \\ref{supp:tab2}**）。  \n\n5. **超参数与训练细节**  \n   - **第一阶段（单视角模型）**：  \n     - 优化器：AdamW，学习率调度器：OneCycleLR。  \n     - 批量大小：32，训练周期：250。  \n   - **第二阶段（适配器微调）**：  \n     - 优化器：AdamW，学习率调度器：分段步长调度。  \n     - 批量大小：16，训练周期：36（语义分割）或12（目标检测）。  \n\n6. **类别级结果**  \n   - **高精度类别**：  \n     - **墙（wall）**：ScanNet IoU **97.1%**，SceneNN IoU **82.6%**。  \n     - **地板（floor）**：ScanNet IoU **97.1%**，SceneNN IoU **82.6%**。  \n   - **低精度类别**：  \n     - **窗帘（curtain）**：ScanNet IoU **58.9%**，SceneNN IoU **50.2%**。  \n     - **浴缸（bathtub）**：ScanNet IoU **94.2%**，SceneNN IoU **未报告**（可能因数据集缺失）。  \n\n7. **对比与创新点**  \n   - **对比现有方法**：  \n     - 无需任务特定设计（如 \\cite{rukhovich2022fcaf3d} 的FCAF3D）。  \n     - 通过3D NMS直接生成实例掩码，避免复杂融合策略。  \n   - **创新点**：  \n     - **内存基适配器**：动态缓存历史特征以增强当前帧的语义理解。  \n     - **跨帧特征融合**：利用注意力机制实现多帧信息的高效聚合。  \n\n---  \n以上段落涵盖了模型架构、训练细节、实验结果及创新点，完整呈现了内存基适配器的核心思想与实现方式。",
  "extraction_method": "LLM-based"
}
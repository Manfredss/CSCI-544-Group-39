{
  "summary": "Memory-based adapters enable temporal feature aggregation and cross-modal learning, enhancing offline models for sequ...",
  "caption": "Overall architecture of our approach. We insert memory-based adapters after image and point cloud backbones, which cache the extracted features in memory over time and perform temporal aggregation. 3D-to-2D adapter is proposed to further exploit inter-modal temporal information. Solid lines indicate operations within a single frame, while dashed lines indicate temporal operations.",
  "label": "over-arch",
  "extracted_context": "**Relevant Context Paragraphs:**\n\n1. **Figure Caption (over-arch):**  \n   *\"Overall architecture of our approach. We insert memory-based adapters after image and point cloud backbones, which cache the extracted features in memory over time and perform temporal aggregation. 3D-to-2D adapter is proposed to further exploit inter-modal temporal information. Solid lines indicate operations within a single frame, while dashed lines indicate temporal operations.\"*  \n   *(This directly describes the model's architecture, emphasizing the role of memory-based adapters and cross-modal temporal learning.)*\n\n2. **Supplementary Material - Detailed Architecture (Section 1):**  \n   *\"For online 3D semantic segmentation, we use U-Net [...] as the image backbone and Minkowski-UNet [...] as the point cloud backbone [...] For online 3D object detection, we adopt ResNet [...] with FPN [...] as the image backbone and FCAF3D [...] as the point cloud backbone [...] For online 3D instance segmentation, we use the same image backbone [...] and adopt TD3D [...] as the point cloud backbone [...] Note that for TD3D, the backbone maintains a high-resolution scene representation for ROI-wise instance prediction. We construct a point cloud memory to cache this scene representation, which ensures the point clouds within each ROI are the most complete up to current time. This design helps us acquire complete instance mask by simply performing 3D NMS, which avoids complicated mask fusion strategy [...] to merge instance masks of different frames.\"*  \n   *(This section explains how adapters are integrated into specific backbones and their role in maintaining temporal consistency and instance-level completeness.)*\n\n3. **Main Paper - Introduction/Conclusion (Implied Context):**  \n   *\"By equipping offline models with our modules, we achieve leading performance on three scene perception tasks compared with state-of-the-art online methods, even without any model and task-specific designs.\"*  \n   *(This highlights the key contribution: enabling offline models to adapt to sequential inputs via memory-based adapters, reducing task-specific engineering.)*\n\n4. **Supplementary Material - Training Hyperparameters (Section 2):**  \n   *\"We train the online perception models in two stages. [...] For online semantic segmentation, we set max epoch as 250 [...] Then we set max epoch as 36 [...] for the second stage. [...] For online object detection, we set max epoch as 12 [...] Then we adopt the same hyperparameters for finetuning in the second stage. [...] For online instance segmentation, we set max epoch as 33 [...] Then we adopt the same hyperparameters for finetuning.\"*  \n   *(This provides context on training protocols, emphasizing the adaptability of the framework across tasks.)*\n\n5. **Class-specific Results (Section 3):**  \n   *\"We provide class-specific experimental results [...] Table [supp:tab1] and [supp:tab2] show the 3D semantic segmentation results [...] Table [supp:tab3] and [supp:tab4] show the 3D object detection results [...] Table [supp:tab5] and [supp:tab6] show the 3D object detection results [...]\"*  \n   *(This validates the effectiveness of the architecture across diverse object categories, reinforcing the robustness of the memory-based design.)*\n\n**Summary of Key Context:**  \nThe figure and surrounding text emphasize the integration of memory-based adapters into backbones for temporal feature aggregation, the cross-modal 3D-to-2D adapter for inter-modal temporal learning, and the adaptability of the framework across tasks (segmentation, detection, instance segmentation). The architecture's design prioritizes temporal consistency and reduces task-specific engineering, validated by class-specific performance metrics.",
  "extraction_method": "LLM-based"
}
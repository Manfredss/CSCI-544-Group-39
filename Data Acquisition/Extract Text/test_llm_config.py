#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• LLM é…ç½®å’Œè¿æ¥
"""

import sys
import json
from pathlib import Path

def test_config():
    """æµ‹è¯•é…ç½®æ–‡ä»¶"""
    config_path = Path("Data Acquisition/Extract Text/config.yaml")
    
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    
    try:
        import yaml
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ ({config_path.name})")
        print(f"   Provider: {config.get('llm_provider', 'unknown')}")
        return True
    except ImportError:
        print("âŒ ç¼ºå°‘ PyYAML åº“ï¼Œè¯·è¿è¡Œ: pip install pyyaml")
        return False
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶è§£æå¤±è´¥: {e}")
        return False

def test_ollama():
    """æµ‹è¯• Ollama è¿æ¥"""
    try:
        import requests
        print("\næµ‹è¯• Ollama è¿æ¥...")
        
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            print(f"âœ… Ollama è¿æ¥æˆåŠŸï¼Œå¯ç”¨æ¨¡å‹æ•°: {len(models)}")
            if models:
                print("   å¯ç”¨æ¨¡å‹:")
                for model in models[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"   - {model.get('name', 'unknown')}")
            return True
        else:
            print(f"âŒ Ollama å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except ImportError:
        print("âŒ ç¼ºå°‘ requests åº“ï¼Œè¯·è¿è¡Œ: pip install requests")
        return False
    except Exception as e:
        print(f"âŒ Ollama è¿æ¥å¤±è´¥: {e}")
        print("   æç¤ºï¼šç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ (ollama serve)")
        return False

def test_openai():
    """æµ‹è¯• OpenAI é…ç½®"""
    import os
    print("\næµ‹è¯• OpenAI é…ç½®...")
    
    api_key = os.environ.get("OPENAI_API_KEY")
    if api_key:
        print(f"âœ… ç¯å¢ƒå˜é‡ OPENAI_API_KEY å·²è®¾ç½® (é•¿åº¦: {len(api_key)})")
        return True
    else:
        print("âš ï¸  ç¯å¢ƒå˜é‡ OPENAI_API_KEY æœªè®¾ç½®")
        print("   å¦‚éœ€ä½¿ç”¨ OpenAIï¼Œè¯·è®¾ç½®: export OPENAI_API_KEY=sk-xxx...")
        return False

def test_llm_simple():
    """ç®€å• LLM æµ‹è¯•"""
    print("\næ‰§è¡Œç®€å• LLM æµ‹è¯•...")
    
    config_path = Path("Data Acquisition/Extract Text/config.yaml")
    
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    
    try:
        import yaml
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        provider = config.get('llm_provider')
        
        if provider == 'ollama':
            print("   ä½¿ç”¨ Ollama è¿›è¡Œæµ‹è¯•...")
            import requests
            url = "http://localhost:11434/api/generate"
            payload = {
                "model": config['ollama']['model'],
                "prompt": "Hello, respond with just 'OK'",
                "stream": False
            }
            response = requests.post(url, json=payload, timeout=30)
            response.raise_for_status()
            result = response.json()
            output = result.get("response", "").strip()
            print(f"âœ… Ollama æµ‹è¯•æˆåŠŸï¼Œå“åº”: {output[:50]}")
            return True
            
        elif provider == 'openai':
            print("   ä½¿ç”¨ OpenAI è¿›è¡Œæµ‹è¯•...")
            import requests
            import os
            
            api_key_spec = config['openai']['api_key']
            if api_key_spec.startswith("ENV:"):
                api_key = os.environ.get(api_key_spec[4:])
            else:
                api_key = api_key_spec
            
            if not api_key:
                print("âŒ API Key æœªé…ç½®")
                return False
            
            url = f"{config['openai']['base_url']}/chat/completions"
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": config['openai']['model'],
                "messages": [{"role": "user", "content": "Hello, respond with just 'OK'"}],
                "max_tokens": 10
            }
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            response.raise_for_status()
            result = response.json()
            output = result['choices'][0]['message']['content']
            print(f"âœ… OpenAI æµ‹è¯•æˆåŠŸï¼Œå“åº”: {output[:50]}")
            return True
        else:
            print(f"âŒ æœªçŸ¥çš„ provider: {provider}")
            return False
            
    except Exception as e:
        print(f"âŒ LLM æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("=" * 60)
    print("LLM é…ç½®æµ‹è¯•")
    print("=" * 60)
    
    results = []
    
    # æµ‹è¯•é…ç½®æ–‡ä»¶
    results.append(("é…ç½®æ–‡ä»¶", test_config()))
    
    # æµ‹è¯• Ollama
    results.append(("Ollama è¿æ¥", test_ollama()))
    
    # æµ‹è¯• OpenAI
    results.append(("OpenAI é…ç½®", test_openai()))
    
    # ç®€å• LLM æµ‹è¯•
    results.append(("LLM åŠŸèƒ½", test_llm_simple()))
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name:15s} : {status}")
    
    print("\nå»ºè®®:")
    provider = None
    try:
        import yaml
        config_path = Path("Data Acquisition/Extract Text/config.yaml")
        if config_path.exists():
            with open(config_path, 'r') as f:
                provider = yaml.safe_load(f).get('llm_provider')
    except:
        pass
    
    if provider == 'ollama':
        if not results[1][1]:  # Ollama è¿æ¥å¤±è´¥
            print("- å¯åŠ¨ Ollama æœåŠ¡: ollama serve")
            print("- æ‹‰å–æ¨¡å‹: ollama pull qwen3:8b")
    elif provider == 'openai':
        if not results[2][1]:  # OpenAI é…ç½®å¤±è´¥
            print("- è®¾ç½® API Key: export OPENAI_API_KEY=sk-xxx...")
    
    all_passed = all(r[1] for r in results)
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥è¿è¡Œ extract_text_llm.py")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ ¹æ®æç¤ºä¿®å¤é—®é¢˜")
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    sys.exit(main())

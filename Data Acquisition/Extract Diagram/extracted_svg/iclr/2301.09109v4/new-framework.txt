. For each user-$i$, FedRAP utilizes its ratings $r_i$ as labels to locally train a user embedding $_i$ and a local item embedding $^{(i)}$. By adding $^{(i)}$ to the global item embedding $$ from the server, i.e., , FedRAP creates a personalized item embedding based on both shared knowledge and personal perspective and thus produces better recommendations. Since clients and server only communicate $$, FedRAP enforce its sparsity to reduce the communication cost and encourage its difference to $^{(i)}$ so they are complementary.-1